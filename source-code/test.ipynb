{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FakeBrCorpus:\n",
    "- Dataset: https://github.com/roneysco/Fake.br-Corpus\n",
    "- Docs: https://sites.icmc.usp.br/taspardo/PROPOR2018-MonteiroEtAl.pdf\n",
    "\n",
    "TwitterBR:\n",
    "- Dataset: https://github.com/phfaustini/BRACIS2019_FAKENEWS\n",
    "- Docs: https://ieeexplore.ieee.org/document/8923888/footnotes#footnotes\n",
    "\n",
    "fake_real_news_dataset:\n",
    "- Dataset: https://github.com/GeorgeMcIntire/fake_real_news_dataset\n",
    "- Docs: https://ieeexplore.ieee.org/abstract/document/8257971/footnotes#footnotes\n",
    "\n",
    "Fakenewsdata1\n",
    "- Dataset: https://github.com/rpitrust/fakenewsdata1\n",
    "- Docs: https://arxiv.org/pdf/1703.09398.pdf\n",
    "\n",
    "News-credibility\n",
    "- Dataset: https://github.com/mhardalov/news-credibility\n",
    "- Docs: https://arxiv.org/pdf/1911.08125.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "import gensim, nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.test.gensim_fixt import setup_module\n",
    "from gensim.models import word2vec\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/knguyen02311/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setup_module()\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = '/media/knguyen02311/Data Disk/DataScience/data_mining/is252/TermProject/'\n",
    "STOP_WORDS = nltk.corpus.stopwords.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_br_corpus_df = pd.read_csv(os.path.join(PROJECT_DIR, 'dataset/Fake.br-Corpus/preprocessed/pre-processed.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7200 entries, 0 to 7199\n",
      "Data columns (total 3 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   index              7200 non-null   int64 \n",
      " 1   label              7200 non-null   object\n",
      " 2   preprocessed_news  7200 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 168.9+ KB\n"
     ]
    }
   ],
   "source": [
    "fake_br_corpus_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'katia abreu diz vai colocar expulsao moldura nao reclamar senadora katia abreu disse expulsao pmdb resultado acao cupula atual legenda segundo oportunista amanha vou botar moldura dourada expulsao porque maos onde veio atestado boa conduta curriculo pessoas expulsaram nao servem pais servem pais beneficios proprios disse katia abreu ue expulsao algo tao bom curriculo tanta choradeira katia sabemos motivo provavelmente katia nao valor pt partido ja deveria absorvido parece pt gostava katia somente ficasse entrincheirada dentro pmdb rebaixar demais resta katia ficar chorando pitangas todos cantos tempo ate momento pt nao cadastrou katia abreu fileiras situacao patetica agricultura dilma'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_br_corpus_df.loc[0, :][\"preprocessed_news\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>preprocessed_news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6353</th>\n",
       "      <td>6353</td>\n",
       "      <td>true</td>\n",
       "      <td>odebrecht doou r milhao maguito daniel vilela ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3033</th>\n",
       "      <td>3033</td>\n",
       "      <td>fake</td>\n",
       "      <td>guerra nuclear pode comecar qualquer momento t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>2020</td>\n",
       "      <td>fake</td>\n",
       "      <td>expressao lula diz tudo acabou sonho bandidos ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>1022</td>\n",
       "      <td>fake</td>\n",
       "      <td>anatel afirma prioridade universalizacao banda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677</th>\n",
       "      <td>2677</td>\n",
       "      <td>fake</td>\n",
       "      <td>integrantes mst confessam governo aluga varios...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6674</th>\n",
       "      <td>6674</td>\n",
       "      <td>true</td>\n",
       "      <td>buraco negro informacao seguranca publica bras...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3712</th>\n",
       "      <td>3712</td>\n",
       "      <td>true</td>\n",
       "      <td>anthony garotinho ouvido vez sobre suposta agr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4696</th>\n",
       "      <td>4696</td>\n",
       "      <td>true</td>\n",
       "      <td>primeira turma stf discute nesta terca pedido ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5798</th>\n",
       "      <td>5798</td>\n",
       "      <td>true</td>\n",
       "      <td>julio andrade explica atuar via mao dupla inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>682</td>\n",
       "      <td>fake</td>\n",
       "      <td>pastor igreja eike irrita dispara seguido cris...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index label                                  preprocessed_news\n",
       "6353   6353  true  odebrecht doou r milhao maguito daniel vilela ...\n",
       "3033   3033  fake  guerra nuclear pode comecar qualquer momento t...\n",
       "2020   2020  fake  expressao lula diz tudo acabou sonho bandidos ...\n",
       "1022   1022  fake  anatel afirma prioridade universalizacao banda...\n",
       "2677   2677  fake  integrantes mst confessam governo aluga varios...\n",
       "6674   6674  true  buraco negro informacao seguranca publica bras...\n",
       "3712   3712  true  anthony garotinho ouvido vez sobre suposta agr...\n",
       "4696   4696  true  primeira turma stf discute nesta terca pedido ...\n",
       "5798   5798  true  julio andrade explica atuar via mao dupla inte...\n",
       "682     682  fake  pastor igreja eike irrita dispara seguido cris..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_br_corpus_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_label(label):\n",
    "   return 1 if label == 'true' else 0\n",
    "\n",
    "def build_corpus(data):\n",
    "   \"Creates a list of lists containing words from each sentence\"\n",
    "   corpus = []\n",
    "   for col in ['preprocessed_news']:\n",
    "      for sentence in data[col].items():\n",
    "         word_list = sentence[1].split(\" \")\n",
    "         corpus.append(word_list)\n",
    "   return corpus\n",
    "\n",
    "\n",
    "def vectorize(splited_sentence, w2v_model):\n",
    "   # words_vecs = []\n",
    "   # for word in splited_sentence:\n",
    "   #    if word in w2v_model.wv:\n",
    "   #       words_vecs.append(w2v_model.wv[word])\n",
    "   #    else:\n",
    "   #       words_vecs.append(np.zeros((100)))\n",
    "   # return words_vecs\n",
    "   # # return words_vecs.mean(axis=0)\n",
    "   \n",
    "   words_vecs = [w2v_model.wv[word] for word in splited_sentence if word in w2v_model.wv]\n",
    "   if len(words_vecs) == 0:\n",
    "      return np.zeros(100)\n",
    "   words_vecs = np.array(words_vecs)\n",
    "   return words_vecs.mean(axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7200"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = build_corpus(fake_br_corpus_df)\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = word2vec.Word2Vec(corpus, vector_size=100, window=10, min_count=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00592661,  0.11762395, -0.047673  ,  0.2911397 , -0.09126366,\n",
       "       -0.1467089 ,  0.12433521,  0.51715237, -0.37797466, -0.05832652,\n",
       "        0.18548086, -0.20148583,  0.1525664 ,  0.07050457, -0.20804682,\n",
       "       -0.29897416,  0.01424311, -0.01313357, -0.03835886, -0.44936225,\n",
       "        0.19281858,  0.0565613 ,  0.1801666 ,  0.0044343 ,  0.00378894,\n",
       "        0.16297264, -0.22955807,  0.11046262, -0.35011488,  0.09588832,\n",
       "        0.07435477,  0.11931235, -0.233192  , -0.09000166,  0.05756364,\n",
       "       -0.01630505,  0.19297482, -0.21479686, -0.23306113, -0.5257807 ,\n",
       "       -0.14618424, -0.47525924,  0.04754307,  0.24647847,  0.18877034,\n",
       "       -0.15178062, -0.50294495, -0.03916204, -0.11257908, -0.06662774,\n",
       "       -0.08864307, -0.15645152, -0.1386384 , -0.05662479, -0.19408882,\n",
       "        0.24928996,  0.27915874,  0.17389366, -0.2708606 , -0.10224747,\n",
       "        0.05099581,  0.12525883, -0.11591211,  0.00185504,  0.14562128,\n",
       "        0.36829522,  0.0059851 ,  0.40124655, -0.00548349,  0.06677394,\n",
       "       -0.08605898,  0.1382964 ,  0.11066391,  0.02669574,  0.15515266,\n",
       "        0.3916466 , -0.05875645,  0.12081435, -0.21519141,  0.18571681,\n",
       "       -0.06597007, -0.4513027 , -0.020224  ,  0.05967649, -0.04715166,\n",
       "        0.00718177, -0.14904726,  0.08120075,  0.27739784,  0.05986822,\n",
       "        0.0999734 ,  0.13402623,  0.10523078, -0.03390281,  0.4715965 ,\n",
       "        0.17658116,  0.16848359, -0.26747593,  0.08650906,  0.10596354],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv['curriculo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_br_corpus_df['label'].apply(one_hot_label).to_numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7200, 100), (7200,))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([vectorize(sentence, word2vec_model) for sentence in corpus])\n",
    "y = fake_br_corpus_df['label'].apply(one_hot_label).to_numpy().ravel()\n",
    "\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model, _X, _y, folds=5):\n",
    "      _scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "      results = cross_validate(estimator=model,\n",
    "                               X=_X,\n",
    "                               y=_y,\n",
    "                               cv=folds,\n",
    "                               scoring=_scoring,\n",
    "                               return_train_score=True)\n",
    "      \n",
    "      return {\"Training Accuracy scores\": results['train_accuracy'],\n",
    "              \"Mean Training Accuracy\": results['train_accuracy'].mean()*100,\n",
    "              \"Training Precision scores\": results['train_precision'],\n",
    "              \"Mean Training Precision\": results['train_precision'].mean(),\n",
    "              \"Training Recall scores\": results['train_recall'],\n",
    "              \"Mean Training Recall\": results['train_recall'].mean(),\n",
    "              \"Training F1 scores\": results['train_f1'],\n",
    "              \"Mean Training F1 Score\": results['train_f1'].mean(),\n",
    "              \"Validation Accuracy scores\": results['test_accuracy'],\n",
    "              \"Mean Validation Accuracy\": results['test_accuracy'].mean()*100,\n",
    "              \"Validation Precision scores\": results['test_precision'],\n",
    "              \"Mean Validation Precision\": results['test_precision'].mean(),\n",
    "              \"Validation Recall scores\": results['test_recall'],\n",
    "              \"Mean Validation Recall\": results['test_recall'].mean(),\n",
    "              \"Validation F1 scores\": results['test_f1'],\n",
    "              \"Mean Validation F1 Score\": results['test_f1'].mean()\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB: 68.33333333333333\n",
      "KNN: 67.54166666666667\n",
      "SVM: 79.94444444444446\n",
      "RF: 84.625\n"
     ]
    }
   ],
   "source": [
    "model_naivebayes = BernoulliNB()\n",
    "model_knn = KNeighborsClassifier(n_neighbors=7)\n",
    "model_svm = SVC(kernel='linear', gamma='auto')\n",
    "model_rf = RandomForestClassifier(n_estimators=951)\n",
    "\n",
    "print('NB:', cross_validation(model_naivebayes, x, y)['Mean Validation Accuracy'])\n",
    "print('KNN:', cross_validation(model_knn, x, y)['Mean Validation Accuracy'])\n",
    "print('SVM:', cross_validation(model_svm, x, y)['Mean Validation Accuracy'])\n",
    "print('RF:', cross_validation(model_rf, x, y)['Mean Validation Accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
